[{src:'onDidChangeTextDocument',msg:'%s:%s to %s:%s in [%s] replaced with: %s`',prm:['0','0','0','0','git/scm0/input',''],time:'2024-09-12T04:03:53.505Z'},{src:'onDidChangeTextDocument',msg:'%s:%s to %s:%s in [%s] replaced with: %s`',prm:['0','0','0','0','git/scm0/input',''],time:'2024-09-12T04:03:53.515Z'},{src:'onDidChangeTextDocument',msg:'%s:%s to %s:%s in [%s] replaced with: %s`',prm:['75','0','495','0','/Users/burakyetistiren/Desktop/warning_suppression/code/simulate.py.git',"    #print(sorted_warnings)\n    return sorted_warnings\n\ndef initialize_warnings_state(ground_truth):\n    \"\"\"Initialize all warnings with the state 'uninspected'.\"\"\"\n    return {k: 'uninspected' for k in ground_truth.keys()}\n\ndef calculate_accuracy(warnings_state, ground_truth):\n    \"\"\"Calculate the accuracy by comparing the current state of warnings with the ground truth.\"\"\"\n    correct_labels = sum(1 for k, v in warnings_state.items() if v == ground_truth[k])\n    return correct_labels / len(ground_truth) * 100\n\ndef get_number_of_uninspected_warnings_of_rule(rule_number, model):\n    # rule_predict_pos<number>(<warning>)\n    uninspected_warnings = []\n    for line in model:\n        matches_rule = line.startswith(f'rule_predict_pos{rule_number}') if rule_number != 0 else line.startswith('rule_predict_pos(')\n        if matches_rule:\n            # extract warning from parenthesis\n            warning = line.split('(')[1].split(')')[0]\n            if warning not in ground_truth:\n                continue\n            if warnings_state[warning] == 'uninspected':\n                uninspected_warnings.append(warning)\n    return len(uninspected_warnings)\n\ndef get_number_of_most_uninspected_warnings_of_rule(rules, model):\n    max_uninspected = 0\n    rule_number = 0\n    for rule in rules:\n        num_uninspected = get_number_of_uninspected_warnings_of_rule(rule, model)\n        if num_uninspected > max_uninspected:\n            max_uninspected = num_uninspected\n            rule_number = rule\n    return rule_number, max_uninspected\n\n\ndef sample_labels_randomized_then_sorted(ground_truth, num_pos, num_neg, code_data, warnings_state, apply_heuristics=None, sampling_ratio=0.5, warning_ids=None):\n    \"\"\"\n    Apply specified heuristics to the warnings before sampling:\n    - apply_heuristics: A list containing the numbers [1, 2, 3] corresponding to the heuristics to apply.\n        1: Review the shorter code first.\n        2: Look for similar code (shared API calls).\n        3: Look for neighbor classes (contained in the same package or directory).\n    - If warning_ids is provided, apply the heuristics to only those warnings.\n    - After applying heuristics, select either one positive or one negative warning based on a coin toss.\n    \"\"\"\n    if apply_heuristics is None:\n        apply_heuristics = [1, 2, 3]  # Default to applying all heuristics\n\n    # Determine which warnings to operate on: either from ground_truth or passed warning_ids\n    if warning_ids:\n        warnings = [\n            (k, code_data.get(int(k), {}).get('linesOfCode', 0), code_data.get(int(k), {}).get('functionCalls', []), 'uninspected')\n            for k in warning_ids if warnings_state.get(k) == 'uninspected'\n        ]\n        #here print(warning_ids)\n        #here print(' warnings:', warnings)\n    else:\n        # Get all uninspected warnings with their lines of code and function calls\n        warnings = [\n            (k, code_data.get(int(k), {}).get('linesOfCode', 0), code_data.get(int(k), {}).get('functionCalls', []), 'uninspected')\n            for k, v in ground_truth.items() if warnings_state[k] == 'uninspected'\n        ]\n\n    # Shuffle the warnings and sample based on the sampling ratio\n    random.shuffle(warnings)\n    if len(warnings) > 1:\n        warnings = warnings[:int(len(warnings) * sampling_ratio)]\n    \n    if not warnings:  # If all warnings have been inspected or none passed, return empty lists\n        return [], []\n    \n    # Apply heuristics in the specified order\n    containment = read_containment()\n    #print(containment)\n    for heuristic in apply_heuristics:\n        if heuristic == 1:\n            warnings = heuristic_shorter_code_first(warnings)\n        elif heuristic == 2:\n            warnings = heuristic_shared_function_calls(warnings)\n        elif heuristic == 3:\n            warnings = heuristic_neighbor_classes(warnings, containment)\n        elif heuristic == 4:\n            # choose a random heuristic\n            warnings = random.choice([heuristic_shorter_code_first(warnings), \n                                      heuristic_shared_function_calls(warnings), \n                                      heuristic_neighbor_classes(warnings, containment)])\n\n    # Sort by code length to identify shortest and longest warnings\n    sorted_warnings_by_length = sorted(warnings, key=lambda x: x[1])\n\n    # Classify warnings as positive or negative based on their position in the sorted list\n    for i in range(len(warnings)):\n        if warnings[i] in sorted_warnings_by_length[:len(sorted_warnings_by_length)//2]:\n            warnings[i] = list(warnings[i])\n            warnings[i][3] = 'positive'\n            warnings[i] = tuple(warnings[i])\n        else:\n            warnings[i] = list(warnings[i])\n            warnings[i][3] = 'negative'\n            warnings[i] = tuple(warnings[i])    \n    \n    # Coin toss to decide whether to pick a positive or negative warning\n    coin_toss = random.choice(['positive', 'negative'])\n    \n    if coin_toss == 'positive':\n        # Select the shortest warning for positive\n        selected_positive_warnings = [warnings[0][0]]\n        selected_negative_warnings = []\n        warnings_state[selected_positive_warnings[0]] = 'positive'\n    else:\n        # Select the longest warning for negative\n        selected_positive_warnings = []\n        selected_negative_warnings = [warnings[-1][0]]\n        warnings_state[selected_negative_warnings[0]] = 'negative'\n    \n    print('Selected positive warning:', selected_positive_warnings)\n    print('Selected negative warning:', selected_negative_warnings)\n    \n    return selected_positive_warnings, selected_negative_warnings\n\n\n\ndef run_clingo():\n    files = [\n        f'lp/simulation_labels.lp',  \n        'lp/background.lp',              \n        'lp/frozen_rules.lp',            \n        'lp/rules2.lp'                   \n    ]\n    \n    command = ['clingo'] + files + ['--outf=2'] + ['--time-limit=30'] \n    print(' '.join(command))\n    result = subprocess.run(command, capture_output=True, text=True)\n\n    return result.stdout\n\ndef parse_clingo_output(data):\n    # Load the data using json.loads if 'data' is a string,\n    # otherwise assume it's already a dictionary\n    if isinstance(data, str):\n        #print(data)\n        data = json.loads(data.replace(\"'\", '\"'))\n    # Navigate through the JSON structure\n    # Assuming 'Call' is always present and has at least one element\n    calls = data.get(\"Call\", [])\n    if calls:\n        # Assuming 'Witnesses' is always present in the last element of 'Call' and has at least one element\n        last_call = calls[-1]\n        witnesses = last_call.get(\"Witnesses\", [])\n        if witnesses:\n            # Get the last 'Witnesses' entry\n            last_witness = witnesses[-1]\n            # Return the 'Value' list from the last 'Witnesses' entry\n            return last_witness.get(\"Value\", [])\n    return []\n\ndef extract_summary_rules(clingo_output):\n    # a summary rule is one prefixed by rule_contains(number)\n    summary_rules_by_prefix = defaultdict(list)\n    for line in clingo_output:\n        if line.startswith('rule_contains'):\n\n            number_str = line.split('(')[0].split('rule_contains')[1]\n            number = int(number_str) if number_str.isdigit() else 0\n\n            rule = line.split('(')[1].split(')')[0]\n            summary_rules_by_prefix[number].append(rule)\n    return summary_rules_by_prefix\n\ndef calculate_rule_percentage(clingo_output, positive_predictions):\n    summary_rules_by_prefix = defaultdict(list)\n    rule_percentages = {}\n    for line in clingo_output:\n        if line.startswith('rule_predict_pos'):\n            number_str = line.split('(')[0].split('rule_predict_pos')[1]\n            if number_str == '':\n                number_str = '0'\n            number = int(number_str)\n            warning_number = line.split('(')[1].split(')')[0]\n            summary_rules_by_prefix[number].append(warning_number)\n    for rule_number, matched_warnings in summary_rules_by_prefix.items():\n        rule_percentages[rule_number] = len(set(matched_warnings) & set(positive_predictions)) / len(set(matched_warnings))\n    return rule_percentages\n\ndef number_of_rules_over_percentage(percentages, percentage_threshold=0.8):\n    return sum(1 for p in percentages.values() if p >= percentage_threshold)\n\ndef get_number_of_positive_predictions(clingo_output):\n    positive_predictions = set()\n    for line in clingo_output:\n        if line.startswith('rule_predict_pos'):\n            warning_number = line.split('(')[1].split(')')[0]\n            positive_predictions.add(warning_number)\n    return len(positive_predictions)\n\n\ndef get_positive_predictions(clingo_output, rule_numbers):\n    # rule_predict_pos<number>(<warning>)\n    positive_predictions = []\n    for line in clingo_output:\n        if line.startswith('rule_predict_pos'):\n            number_str = line.split('(')[0].split('rule_predict_pos')[1]\n            number = int(number_str) if number_str.isdigit() else 0\n            if number not in rule_numbers:\n                continue\n            # extract warning from parenthesis\n            warning = line.split('(')[1].split(')')[0]\n            if warning not in ground_truth:\n                continue\n            positive_predictions.append(warning)\n    return positive_predictions\n\ndef get_positive_predictions_of_rule(clingo_output, rule_number):\n    # rule_predict_pos<number>(<warning>)\n    positive_predictions = []\n    # here print('rule_predict_pos' + str(rule_number))\n    for line in clingo_output:\n        matches_rule = line.startswith(f'rule_predict_pos{rule_number}') if rule_number != 0 else line.startswith('rule_predict_pos(')\n        if matches_rule:\n            # extract warning from parenthesis\n            warning = line.split('(')[1].split(')')[0]\n            if warning not in ground_truth:\n                continue\n            positive_predictions.append(warning)\n    return positive_predictions    \n\n# Simulation driver code\n\n# Parameters for the simulation\nwarning_type = sys.argv[1]\nground_truth_file = sys.argv[2]\n\n# Read ground_truth data\nground_truth = read_ground_truth(ground_truth_file)\n\ngraph_id_to_warning = {}\nwith open('meteor_app/private/original_graphs/' + warning_type + '_graph_id_mapping.txt', 'r') as file:\n    for line in file:\n        graph_id = line.split(',')[1]\n        example_id = line.split(',')[2].split(' - ')[0]\n        graph_id_to_warning[graph_id] = example_id\n\n# Load code data from JSON\nwith open('meteor_app/private/original_graphs/' + warning_type + '_elementpositions.json', 'r') as file:\n    code_content_data = json.load(file)\n\ncode_data = {}\n\nfor graph_id_str, another_json_str in code_content_data.items():\n    warning_data = json.loads(another_json_str)\n\n    # Code length\n    raw_code = warning_data.get(\"rawCode\", \"\")\n    raw_code_length = len(raw_code.splitlines())\n    try:\n        warning_id = int(graph_id_to_warning[graph_id_str])\n    except:\n        continue\n\n    code_data[warning_id] = {}\n\n    code_data[warning_id]['linesOfCode'] = raw_code_length\n\n    # Find all code expressions that look like function calls\n    function_calls = [expression for expression in warning_data['expressionStart'].keys() if '()' in expression and '->' not in expression]\n\n    code_data[warning_id]['functionCalls'] = function_calls\n\n# Scenarios: 1 = Heuristic 1, 2 = Heuristic 2, 3 = Heuristic 3, 4 = All Heuristics\nscenarios = {\n    #'Heuristic 1 Only': [1],\n    #'Heuristic 2 Only': [2],\n    #'Heuristic 3 Only': [3],\n    'All Heuristics': [4]\n}\n\n# Store the accuracy, rule percentage, and conciseness results for each scenario\naccuracy_results = {key: {'p=0': [], 'p=0.5': [], 'p=1': []} for key in scenarios.keys()}\nrule_percentage_results = {key: {'p=0': [], 'p=0.5': [], 'p=1': []} for key in scenarios.keys()}\nconciseness_results = {key: {'p=0': [], 'p=0.5': [], 'p=1': []} for key in scenarios.keys()}\n\n\n# Run simulations for each scenario\nfor scenario_name, heuristics in scenarios.items():\n    rule_percentage = 0\n    conciseness = 0\n    accuracy = 0\n    for p_value in [1, 0.5, 0]:\n        print(f\"Running scenario: {scenario_name} with p={p_value}\")\n\n        warnings_state = initialize_warnings_state(ground_truth)\n        num_warnings = len(ground_truth)\n\n\n        # get the first warning\n        selected_pos, selected_neg = sample_labels_randomized_then_sorted(ground_truth, 1, 1, code_data, initialize_warnings_state(ground_truth), apply_heuristics=heuristics)\n        for pos in selected_pos:\n            warnings_state[pos] = 'positive'\n        for neg in selected_neg:\n            warnings_state[neg] = 'negative'\n        \n        pos_labels = [k for k, v in warnings_state.items() if v == 'positive']\n        neg_labels = [k for k, v in warnings_state.items() if v == 'negative']\n\n        write_labels_to_clingo_input(pos_labels, neg_labels)\n        output = run_clingo()\n    \n        # Run simulation for # of warnings iterations\n        for iteration in range(num_warnings - 1):\n            if all([v != 'uninspected' for v in warnings_state.values()]):\n                # fill in the rest of the warnings with the last accuracy, rule percentage, and conciseness\n                for i in range(iteration, num_warnings):\n                    accuracy_results[scenario_name][f'p={p_value}'].append(accuracy)\n                    rule_percentage_results[scenario_name][f'p={p_value}'].append(rule_percentage)\n                    conciseness_results[scenario_name][f'p={p_value}'].append(conciseness)\n                break\n            \n            print(f'Simulation Iteration {iteration} for {scenario_name} with p={p_value}')\n\n            if p_value == 1:\n                print('Using rules to select positive/negative warnings')\n                # Use the rules to select positive/negative warnings\n                if output:\n                    model = parse_clingo_output(output)\n                    rule_numbers = list(extract_summary_rules(model).keys())\n                    if rule_numbers:\n                        rule_number_to_check, max_uninspected = get_number_of_most_uninspected_warnings_of_rule(rule_numbers, model)\n                        # here print('Rule number to check:', rule_number_to_check)\n                        # here print('Max uninspected warnings:', max_uninspected)\n                        # here print('Rule numbers:', rule_numbers)\n                        # here print('Model:', model)\n                        if max_uninspected > 0:\n                            selected_all_pos = get_positive_predictions_of_rule(model, rule_number_to_check)\n                            selected_pos, selected_neg = sample_labels_randomized_then_sorted(ground_truth, 1, 1, code_data, warnings_state, apply_heuristics=heuristics, warning_ids=selected_all_pos )\n                            \n                            # 0.05 probability to mark all matching warnings as positive/negative\n                            if random.random() <= 0.05 and iteration > num_warnings // 2:\n                                for pos in selected_all_pos:\n                                    warnings_state[pos] = 'positive'\n                        else:\n                            selected_pos, selected_neg = sample_labels_randomized_then_sorted(ground_truth, 1, 1, code_data, warnings_state, apply_heuristics=heuristics)\n\n\n            elif p_value == 0.5:\n                # 50% chance to use the rules or the original heuristic-based sampling\n                if random.random() < 0.5:\n                    if output:\n                        model = parse_clingo_output(output)\n                        rule_numbers = list(extract_summary_rules(model).keys())\n                        if rule_numbers:\n                            rule_number_to_check, max_uninspected = get_number_of_most_uninspected_warnings_of_rule(rule_numbers, model)\n                            # here print('Rule number to check:', rule_number_to_check)\n                            # here print('Max uninspected warnings:', max_uninspected)\n                            # here print('Rule numbers:', rule_numbers)\n                            # here print('Model:', model)\n                            if max_uninspected > 0:\n                                selected_all_pos = get_positive_predictions_of_rule(model, rule_number_to_check)\n                                selected_pos, selected_neg = sample_labels_randomized_then_sorted(ground_truth, 1, 1, code_data, warnings_state, apply_heuristics=heuristics, warning_ids=selected_all_pos)\n                                \n                                # 0.05 probability to mark all matching warnings as positive/negative\n                                if random.random() <= 0.05 and iteration > num_warnings // 2:\n                                    for pos in selected_all_pos:\n                                        warnings_state[pos] = 'positive'\n                            else:\n                                selected_pos, selected_neg = sample_labels_randomized_then_sorted(ground_truth, 1, 1, code_data, warnings_state, apply_heuristics=heuristics)\n\n                else:\n                    selected_pos, selected_neg = sample_labels_randomized_then_sorted(ground_truth, 1, 1, code_data, warnings_state, apply_heuristics=heuristics)\n\n            elif p_value == 0:\n                # p=0, just use the original heuristic-based sampling\n                selected_pos, selected_neg = sample_labels_randomized_then_sorted(ground_truth, 1, 1, code_data, warnings_state, apply_heuristics=heuristics)\n\n            # Write labels to Clingo input and run Clingo\n            pos_labels = [k for k, v in warnings_state.items() if v == 'positive']\n            neg_labels = [k for k, v in warnings_state.items() if v == 'negative']\n\n            write_labels_to_clingo_input(pos_labels, neg_labels)\n            output = run_clingo()\n            #print('Output:', output)\n\n            if output:\n                model = parse_clingo_output(output)\n                inferred_rules = extract_summary_rules(model)\n                percentages = calculate_rule_percentage(model, pos_labels)\n                num_rules_over_threshold = number_of_rules_over_percentage(percentages)\n                num_rules = len(inferred_rules)\n                number_of_positive_predictions = get_number_of_positive_predictions(model)\n\n                if num_rules_over_threshold > 0:\n                    conciseness = number_of_positive_predictions / num_rules_over_threshold\n                else:\n                    conciseness = 0\n\n                # Calculate the percentage of rules over the threshold\n                if num_rules > 0:\n                    rule_percentage = (num_rules_over_threshold / num_rules) * 100\n                else:\n                    rule_percentage = 0\n\n                rule_percentage_results[scenario_name][f'p={p_value}'].append(rule_percentage)\n                conciseness_results[scenario_name][f'p={p_value}'].append(conciseness)\n\n            # Calculate accuracy after each iteration\n            accuracy = calculate_accuracy(warnings_state, ground_truth)\n            accuracy_results[scenario_name][f'p={p_value}'].append(accuracy)\n            print(f'Accuracy after iteration {iteration}: {accuracy:.2f}%')\n            print(f'Percentage of rules over threshold after iteration {iteration}: {rule_percentage:.2f}%')\n            print(f'Conciseness after iteration {iteration}: {conciseness:.2f}')\n\n# Save the results to a csv file\nif scenario_name == 'Heuristic 1 Only':\n    scenario_name = 'h=1'\nelif scenario_name == 'Heuristic 2 Only':\n    scenario_name = 'h=2'\nelif scenario_name == 'Heuristic 3 Only':\n    scenario_name = 'h=3'\nelif scenario_name == 'All Heuristics':\n    scenario_name = 'h=4'\n\n#scenario_name = ''\n"],time:'2024-09-12T04:04:09.389Z'},{src:'onDidChangeTextDocument',msg:'%s:%s to %s:%s in [%s] replaced with: %s`',prm:['0','0','0','0','git/scm0/input','m'],time:'2024-09-12T04:04:34.227Z'}]