[{src:'onDidChangeActiveTextEditor',msg:'Current editor: [%s]; Previous editor: [%s]',prm:['untitled:Untitled-1',''],time:'2024-09-05T08:24:57.966Z'},{src:'onDidChangeTextEditorSelection',msg:'%s:%s to %s:%s in [%s] text: %s',prm:['282','0','467','0','Untitled-1',"# Scenarios: 1 = Heuristic 1, 2 = Heuristic 2, 3 = Heuristic 3, 4 = All Heuristics\nscenarios = {\n    'Heuristic 1 Only': [1],\n    'Heuristic 2 Only': [2],\n    'Heuristic 3 Only': [3],\n    'All Heuristics': [1, 2, 3]\n}\n\n# Store the accuracy, rule percentage, and conciseness results for each scenario\naccuracy_results = {key: {'p=0': [], 'p=0.5': [], 'p=1': []} for key in scenarios.keys()}\nrule_percentage_results = {key: {'p=0': [], 'p=0.5': [], 'p=1': []} for key in scenarios.keys()}\nconciseness_results = {key: {'p=0': [], 'p=0.5': [], 'p=1': []} for key in scenarios.keys()}\n\n# Run simulations for each scenario\nfor scenario_name, heuristics in scenarios.items():\n    for p_value in [0, 0.5, 1]:\n        print(f\"Running scenario: {scenario_name} with p={p_value}\")\n\n        warnings_state = initialize_warnings_state(ground_truth)\n        num_warnings = len(ground_truth)\n\n        # Run simulation for # of warnings iterations\n        for iteration in range(num_warnings):\n            print(f'Simulation Iteration {iteration} for {scenario_name} with p={p_value}')\n\n            if p_value == 1:\n                # Use the rules to select positive/negative warnings\n                output = run_clingo()\n                if output:\n                    model = parse_clingo_output(output)\n                    rule_numbers = list(extract_summary_rules(model).keys())\n                    if rule_numbers:\n                        selected_pos = get_positive_predictions_of_rule(model, random.choice(rule_numbers))\n                        selected_neg = []  # Handle negative case similarly if needed\n\n                        # 0.1 probability to mark all matching warnings as positive/negative\n                        if random.random() < 0.1:\n                            selected_pos = get_positive_predictions(model, rule_numbers)\n                        # Update states\n                        for pos in selected_pos:\n                            warnings_state[pos] = 'positive'\n\n            elif p_value == 0.5:\n                # 50% chance to use the rules or the original heuristic-based sampling\n                if random.random() < 0.5:\n                    output = run_clingo()\n                    if output:\n                        model = parse_clingo_output(output)\n                        rule_numbers = list(extract_summary_rules(model).keys())\n                        if rule_numbers:\n                            selected_pos = get_positive_predictions_of_rule(model, random.choice(rule_numbers))\n                            selected_neg = []  # Handle negative case similarly if needed\n\n                            # 0.1 probability to mark all matching warnings as positive/negative\n                            if random.random() < 0.1:\n                                selected_pos = get_positive_predictions(model, rule_numbers)\n                            # Update states\n                            for pos in selected_pos:\n                                warnings_state[pos] = 'positive'\n                else:\n                    selected_pos, selected_neg = sample_labels_randomized_then_sorted(ground_truth, 1, 1, code_data, warnings_state, apply_heuristics=heuristics)\n\n            else:\n                # p=0, just use the original heuristic-based sampling\n                selected_pos, selected_neg = sample_labels_randomized_then_sorted(ground_truth, 1, 1, code_data, warnings_state, apply_heuristics=heuristics)\n\n            # Write labels to Clingo input and run Clingo\n            pos_labels = [k for k, v in warnings_state.items() if v == 'positive']\n            neg_labels = [k for k, v in warnings_state.items() if v == 'negative']\n            write_labels_to_clingo_input(pos_labels, neg_labels)\n            output = run_clingo()\n\n            if output:\n                model = parse_clingo_output(output)\n                inferred_rules = extract_summary_rules(model)\n                percentages = calculate_rule_percentage(model, pos_labels)\n                num_rules_over_threshold = number_of_rules_over_percentage(percentages)\n                num_rules = len(inferred_rules)\n                number_of_positive_predictions = get_number_of_positive_predictions(model)\n\n                if num_rules_over_threshold > 0:\n                    conciseness = number_of_positive_predictions / num_rules_over_threshold\n                else:\n                    conciseness = 0\n\n                # Calculate the percentage of rules over the threshold\n                if num_rules > 0:\n                    rule_percentage = (num_rules_over_threshold / num_rules) * 100\n                else:\n                    rule_percentage = 0\n\n                rule_percentage_results[scenario_name][f'p={p_value}'].append(rule_percentage)\n                conciseness_results[scenario_name][f'p={p_value}'].append(conciseness)\n\n            # Calculate accuracy after each iteration\n            print(warnings_state)\n            accuracy = calculate_accuracy(warnings_state, ground_truth)\n            accuracy_results[scenario_name][f'p={p_value}'].append(accuracy)\n            print(f'Accuracy after iteration {iteration}: {accuracy:.2f}%')\n            print(f'Percentage of rules over threshold after iteration {iteration}: {rule_percentage:.2f}%')\n            print(f'Conciseness after iteration {iteration}: {conciseness:.2f}')\n\n\n# Define the color scheme for each heuristic\ncolor_scheme = {\n    'Heuristic 1 Only': 'blue',     # Code Length\n    'Heuristic 2 Only': 'green',    # Code Similarity\n    'Heuristic 3 Only': 'orange',   # Same Containment\n    'All Heuristics': 'red'         # Combined\n}\n\n# Define the textures for each p-value\ntexture_scheme = {\n    'p=0': 'solid',\n    'p=0.5': 'dashed',\n    'p=1': 'dotted'\n}\n\n# Updated heuristic names\nheuristic_names = {\n    'Heuristic 1 Only': 'Code Length',\n    'Heuristic 2 Only': 'Code Similarity',\n    'Heuristic 3 Only': 'Same Containment',\n    'All Heuristics': 'Combined'\n}\n\n# Plot the accuracy over time for all scenarios and probabilities\nplt.figure(figsize=(12, 6))\nfor scenario_name, p_results in accuracy_results.items():\n    for p_value, accuracy_list in p_results.items():\n        plt.plot(\n            range(len(accuracy_list)), \n            accuracy_list, \n            label=f'{heuristic_names[scenario_name]} - {p_value}', \n            color=color_scheme[scenario_name], \n            linestyle=texture_scheme[p_value],\n            marker='o'\n        )\n\nplt.xlabel('Iteration Number')\nplt.ylabel('Accuracy (%)')\nplt.title('Accuracy over Iterations for Different Scenarios and Probabilities')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Plot the percentage of rules over threshold over time for all scenarios and probabilities\nplt.figure(figsize=(12, 6))\nfor scenario_name, p_results in rule_percentage_results.items():\n    for p_value, rule_percentage_list in p_results.items():\n        plt.plot(\n            range(len(rule_percentage_list)), \n            rule_percentage_list, \n            label=f'{heuristic_names[scenario_name]} - {p_value}', \n            color=color_scheme[scenario_name], \n            linestyle=texture_scheme[p_value],\n            marker='o'\n        )\n\nplt.xlabel('Iteration Number')\nplt.ylabel('Percentage of Rules Over Threshold (%)')\nplt.title('Percentage of Rules Over Threshold over Iterations for Different Scenarios and Probabilities')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Plot the conciseness over time for all scenarios and probabilities\nplt.figure(figsize=(12, 6))\nfor scenario_name, p_results in conciseness_results.items():\n    for p_value, conciseness_list in p_results.items():\n        plt.plot(\n            range(len(conciseness_list)), \n            conciseness_list, \n            label=f'{heuristic_names[scenario_name]} - {p_value}', \n            color=color_scheme[scenario_name], \n            linestyle=texture_scheme[p_value],\n            marker='o'\n        )\n\nplt.xlabel('Iteration Number')\nplt.ylabel('Conciseness')\nplt.title('Conciseness over Iterations for Different Scenarios and Probabilities')\nplt.legend()\nplt.grid(True)\nplt.show()\n"],time:'2024-09-05T08:24:57.988Z'},{src:'onDidChangeTextEditorVisibleRanges',msg:'%s:%s to %s:%s [%s]',prm:['256','0','283','13','Untitled-1'],time:'2024-09-05T08:24:57.988Z'},{src:'onDidChangeTextEditorVisibleRanges',msg:'%s:%s to %s:%s [%s]',prm:['263','0','290','80','Untitled-1'],time:'2024-09-05T08:24:57.989Z'},{src:'onDidChangeTextDocument',msg:'%s:%s to %s:%s in [%s] replaced with: %s`',prm:['0','0','468','0','Untitled-1',''],time:'2024-09-05T08:24:59.551Z'},{src:'onDidChangeTextEditorSelection',msg:'%s:%s to %s:%s in [%s] text: %s',prm:['0','0','0','0','Untitled-1',''],time:'2024-09-05T08:24:59.553Z'},{src:'onDidChangeTextEditorVisibleRanges',msg:'%s:%s to %s:%s [%s]',prm:['0','0','0','0','Untitled-1'],time:'2024-09-05T08:24:59.553Z'},{src:'onDidChangeActiveTextEditor',msg:'Current editor: [%s]; Previous editor: [%s]',prm:['','untitled:Untitled-1'],time:'2024-09-05T08:24:59.565Z'},{src:'onDidChangeActiveTextEditor',msg:'Current editor: [%s]; Previous editor: [%s]',prm:['/Users/burakyetistiren/Desktop/warning_suppression/code/simulate.py',''],time:'2024-09-05T08:24:59.593Z'},{src:'onDidChangeTextEditorSelection',msg:'%s:%s to %s:%s in [%s] text: %s',prm:['4','26','4','71','/Users/burakyetistiren/Desktop/warning_suppression/code/simulate.py','infer_warnings_alibaba_nacos_NULL_DEREFERENCE'],time:'2024-09-05T08:24:59.598Z'},{src:'onDidChangeActiveTerminal',msg:'Current terminal: [%s]; Previous terminal: [%s]',prm:['node','zsh'],time:'2024-09-05T11:07:05.275Z'}]